#!/usr/bin/perl
use DBI;

#use strict;
#use Mysql;
#use File::Path;
#use File::PathInfo;
#!/bin/bash
# retrieve the value from the argument, check whether the folder exists, if so, rename the folder to a new one with -master trailing, download a new copy of the same
# then insert the values into the database, match the values from the database and make entry into a text file.
#$val_passed=$ARGV[0];

$urlvalue=$ARGV[0];
$count_val=0;
$doc_severity="NULL";
$unes_severity="NULL";
$ev_severity="NULL";
$ex_severity="NULL";
$search_loc="/home/cto/Desktop/remote_malware_detector/";
$file_name=$search_loc."".$urlvalue;
$download_type="";
$status="";
$query="";
#print $file_name."is ++++++++++++++++++++++ ";
#print $search_loc.$urlvalue;
# find out whether the argument passed, has a folder by its name
$folder_name=$search_loc."".$urlvalue;
print "\n".$folder_name."\n\n";
######################
($sec,$min,$hr,$mday,$mon,$year,$wday,$yday,$isdst) = localtime(time);
$mon++;
$year += 1900;
$download_time= $hr . ":" . $min . ":" . $sec;
$download_date=$year . "-" . $mon . "-" . $mday;

#print $download_time."is the download time";
#print $download_date."is the download date";


#print "Date is " . $year . "-" . $mon . "-" . $mday . "\n";

##############################3
$log_name=$search_loc.$urlvalue."/".$urlvalue.".log";
print $log_name."\n\n";

 if (-e $folder_name) 
 {
	print "The folder exists\n\n";

	print "The url is $urlvalue\n\n";

	if(-e $search_loc."".$urlvalue."-master")
	{
		$download_type="regular";

		print "The master folder also exists\n\n";

		# for unix
		my $d= `date +%d-%H.%M.%S`;
		system(`mv $search_loc$urlvalue $search_loc$urlvalue-$d`);
		print "mv $search_loc$urlvalue $search_loc$urlvalue-$d";
		# for windows
		#$files_deleted = rmtree($search_loc."".$urlvalue, 1);
		
		$mkdir_cmd="mkdir ".$search_loc.$urlvalue;
		print "mkdir $search_loc$urlvalue\n\n";

		print "\n\n\t\t\t\t############WGET#############\t\t\t\t\n\n";
		system(`wget -P $search_loc -r $urlvalue -e robots=off`);
		print "\n\nwget -P $search_loc -r $urlvalue -e robots=off\n\n";

		system(`hashdeep -c md5,sha1 -r $urlvalue > $log_name`);
		print "hashdeep -c md5,sha1 -r $urlvalue > $log_name\n\n";

		$download_query="insert into download_details(url,download_type,download_date,download_time)values('".$urlvalue."','".$download_type."','".$download_date."','".$download_time."')";

		print $download_query."\n\n";

		# the hashdeep command
		$hashdeep_ins_cmd="load data local infile \"" .$log_name."\" into table temp_website_enrolled fields terminated by ',' lines terminated by '\n' ignore 5 lines;";
		# truncate table, because, every time the temp table should contain the newest values;
		$truncate_cmd="truncate temp_website_enrolled";

	} #nested if closes here

		#	print "Exiting as not matching and there is no master folder\n\n";

	elsif(-e $folder_name)
	{
		$download_type="regular";
		print "The folder exists and now in elsif part\n\n";
		$new_folder=$urlvalue."-master";
		system(`mv $search_loc$urlvalue $search_loc$new_folder`);
		print "The file has been renamed";
		$mkdir_cmd="mkdir $urlvalue";
		system(`mkdir $file_name`);
		system(`chmod 777 $file_name`);
		#`cd $file_name`;
		system(`wget -P $search_loc -r $urlvalue -e robots=off`);
		system(`/usr/local/bin/hashdeep -c md5,sha1 -r $urlvalue > $log_name`);
		

		$download_query="insert into download_details(url,download_type,download_date,download_time)values('".$urlvalue."','".	$download_type."','".$download_date."','".$download_time."')";
		print $download_query;
		
		# the hashdeep command
		$hashdeep_ins_cmd="load data local infile \"" .$log_name."\" into table temp_website_enrolled fields terminated by ',' lines terminated by '\n' ignore 5 lines;";
		
		# truncate table, because, every time the temp table should contain the newest values;
		$truncate_cmd="truncate temp_website_enrolled";
	} # elseif closes here
} # if closes here
else
{
		$download_type="master";
		print "The folder does not exists";
		$mkdir_cmd="mkdir ".$urlvalue;
		system(`mkdir $urlvalue`);
		system(`wget -P $search_loc -r $urlvalue -e robots=off`);
		#print ("hashdeep -c md5,sha1 -r $urlvalue > $log_name");
		system(`/usr/local/bin/hashdeep -c md5,sha1 -r $urlvalue > $log_name`);
		$download_query="insert into download_details(url,download_type,download_date,download_time)values('".$urlvalue."','".	$download_type."','".$download_date."','".$download_time."')";
		# the hashdeep command

		$hashdeep_ins_cmd="load data local infile \"" .$log_name."\" into table website_enrolled fields terminated by ',' lines terminated by '\n' ignore 5 lines;";
		# truncate table command, nothing to do here, so commiting the transactions;
		$truncate_cmd="commit";
} # else closes here

		$match_query="SELECT a.size, a.sha1, a.md5,a.filename FROM website_enrolled a, temp_website_enrolled b WHERE a.sha1 != b.sha1 or a.md5!=b.md5";
	
 
	$host = "localhost";
	$database = "SecuNite";
	$tablename = "download_details";
	$user = "root";
	$pw = "secunite";

	 
	
#mysql_local_infile=1;

	$dbh    = DBI->connect("dbi:mysql:database=SecuNite;host=localhost;mysql_local_infile=1;","root","secunite", {'RaiseError' => 1} )|| die "Database connection not made $DBI::errstr";
	
	
	print $download_query."\n\n";
	$sth = $dbh->prepare($download_query);
	$sth->execute or die "SQL Error: $DBI::errstr\n";

	print $truncate_cmd."\n\n";
	$sth = $dbh->prepare($truncate_cmd);
	$sth->execute or die "SQL Error: $DBI::errstr\n";

	print $hashdeep_ins_cmd."\n\n";
	$sth = $dbh->prepare($hashdeep_ins_cmd);
	$sth->execute or die "SQL Error: $DBI::errstr\n";
	
	print $match_query."\n\n";
	$sth = $dbh->prepare($match_query);
	$sth->execute or die "SQL Error: $DBI::errstr\n";
	
	my $dt= `date +%d-%H:%M:%S`;
	$dt =~ s/^\s+|\s+$//g; 
	open (CHANGELOG, '>>/home/cto/Desktop/remote_malware_detector/change.log');
	open FILE, ">".$search_loc."/".$urlvalue."/db-match.txt" or die $!;
	print FILE "Size, SHA1, MD5, Filename\n";
	while (@results = $sth->fetchrow_array()) 
	{	
    		print FILE $results[0].",\t".$results[1].",\t".$results[2].",".$results[3]."\n";
    		print CHANGELOG $dt.",".$results[0].",".$results[1].",".$results[2].",".$results[3]."\n";
    		print $results[0].",\t".$results[1].",\t".$results[2]."\t".$results[3]."\n";
	}
	close FILE;
	close CHANGELOG;

print "End of Crawl\n";
	
	

